{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2402876,"sourceType":"datasetVersion","datasetId":1453154},{"sourceId":7534771,"sourceType":"datasetVersion","datasetId":4388119},{"sourceId":7753099,"sourceType":"datasetVersion","datasetId":4533275},{"sourceId":7753262,"sourceType":"datasetVersion","datasetId":4533384}],"dockerImageVersionId":30096,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# First Order Motion Model for Image Animation\nby Aliaksandr Siarohin, Stéphane Lathuilière, Sergey Tulyakov, Elisa Ricci and Nicu Sebe\n\nImage animation consists of generating a video sequence so that an object in a source image is animated according to the motion of a driving video This Framework addresses this problem without using any annotation or prior information about the specific object to animate.Once trained on a set of videos depicting objects of the same category (e.g. faces, human bodies), this can be applied to any object of this class.\n\nThe model consist of two parts:\n- Motion estimation model : predict dense motion fields\n- Generation model : use source image and results from motion estimation model to generate frame.\n\n![first order motion model architecture](https://aliaksandrsiarohin.github.io/first-order-model-website/pipeline.png)\n\n\n","metadata":{"editable":false}},{"cell_type":"markdown","source":"# Installing Dependencies\n\n- OpenCV : for reading images, video and face detection using cascade classifier to crop faces from images\n- First Motion Model: cloning first order motion from github\n- numpy, matplotlib : for array manipulation and plotting","metadata":{"editable":false}},{"cell_type":"code","source":"!pip install opencv-contrib-python","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-03T19:59:16.899127Z","iopub.execute_input":"2024-03-03T19:59:16.899517Z","iopub.status.idle":"2024-03-03T19:59:23.897186Z","shell.execute_reply.started":"2024-03-03T19:59:16.899478Z","shell.execute_reply":"2024-03-03T19:59:23.896145Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/GTGaganReddy/Projectmldl.git","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:23.89893Z","iopub.execute_input":"2024-03-03T19:59:23.899227Z","iopub.status.idle":"2024-03-03T19:59:24.975635Z","shell.execute_reply.started":"2024-03-03T19:59:23.899195Z","shell.execute_reply":"2024-03-03T19:59:24.974727Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade opencv-python\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:24.977588Z","iopub.execute_input":"2024-03-03T19:59:24.977875Z","iopub.status.idle":"2024-03-03T19:59:32.532199Z","shell.execute_reply.started":"2024-03-03T19:59:24.977832Z","shell.execute_reply":"2024-03-03T19:59:32.531194Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport warnings\nimport urllib.request\nwarnings.filterwarnings(\"ignore\")\nfrom IPython.display import HTML","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.534086Z","iopub.execute_input":"2024-03-03T19:59:32.534371Z","iopub.status.idle":"2024-03-03T19:59:32.539536Z","shell.execute_reply.started":"2024-03-03T19:59:32.534338Z","shell.execute_reply":"2024-03-03T19:59:32.538597Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.540992Z","iopub.execute_input":"2024-03-03T19:59:32.541378Z","iopub.status.idle":"2024-03-03T19:59:32.552916Z","shell.execute_reply.started":"2024-03-03T19:59:32.541342Z","shell.execute_reply":"2024-03-03T19:59:32.551941Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions\n- imread : read and load image from path or url in numpy array.\n- vidread : read and load video from path or url as list of frames in numpy array.\n- vidsave : saving video file\n- display : display video and images as html\n- display_image_grid : display images as grid","metadata":{"editable":false}},{"cell_type":"code","source":"'''\n    params:\n        img_path : path or url to image\n        size : size of image to resize, default: None (do not resize)\n        scale : scale image between 0 and 1 by dividing with 255.0, default: True\n    return:\n        image as numpy array\n'''\ndef imread(img_path, size=None, scale=True):\n    if img_path.startswith(\"http://\") or img_path.startswith(\"https://\") or img_path.startswith(\"www.\"):\n        resp = urllib.request.urlopen(img_path)\n        img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n        img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if size is not None:\n            img = cv2.resize(img, size)\n        if scale:\n            img = np.array(img/255.0)\n        return img\n    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, size)\n    if scale:\n        img = np.array(img/255.0)\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.554015Z","iopub.execute_input":"2024-03-03T19:59:32.554302Z","iopub.status.idle":"2024-03-03T19:59:32.565881Z","shell.execute_reply.started":"2024-03-03T19:59:32.554275Z","shell.execute_reply":"2024-03-03T19:59:32.565136Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    params:\n        video_path : path or url to video\n        size : size of frame to resize, default: None (do not resize)\n        scale : scale image between 0 and 1 by dividing with 255.0, default: True\n    return:\n        list of video frames as numpy array\n'''\ndef vidread(video_path, size=None, scale=True):\n    vc = cv2.VideoCapture(video_path)\n    vid = []\n    while vc.isOpened():\n        ret, img = vc.read()\n        if not ret:\n            break\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        if size is not None:\n            img = cv2.resize(img, size)\n        if scale:\n            img = img/255.0\n        vid.append(img)\n    vc.release()\n    return vid","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.566963Z","iopub.execute_input":"2024-03-03T19:59:32.567264Z","iopub.status.idle":"2024-03-03T19:59:32.581504Z","shell.execute_reply.started":"2024-03-03T19:59:32.567233Z","shell.execute_reply":"2024-03-03T19:59:32.580778Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    params:\n        save_path : path to save video\n        frames : list of video frames as numpy array\n        fps : framerate of video to save, default: 20\n        size : size of video frames to save, default: (256,256)\n    return:\n        None\n'''\ndef vidsave(save_path, frames, fps=20, size=(256,256)):\n    #revert scaling factor of image and convert to uint8\n    frames = np.array(frames)*255.0\n    frames = frames.astype(np.uint8)\n    writer = cv2.VideoWriter(save_path, \n                     cv2.VideoWriter_fourcc(*'MJPG'),\n                     fps, size)\n    for frame in frames:\n        writer.write(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    writer.release()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.582444Z","iopub.execute_input":"2024-03-03T19:59:32.582774Z","iopub.status.idle":"2024-03-03T19:59:32.592405Z","shell.execute_reply.started":"2024-03-03T19:59:32.582747Z","shell.execute_reply":"2024-03-03T19:59:32.591623Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    params:\n        source : source image\n        driving : frames of driving video\n        generated : frames of generated video\n    return:\n        animation to display in html\n'''\ndef display(source, driving, generated=None):\n    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n\n    ims = []\n    for i in range(len(driving)):\n        cols = [source]\n        cols.append(driving[i])\n        if generated is not None:\n            cols.append(generated[i])\n        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n        plt.axis('off')\n        ims.append([im])\n\n    ani = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n    plt.close()\n    return ani","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.59515Z","iopub.execute_input":"2024-03-03T19:59:32.595463Z","iopub.status.idle":"2024-03-03T19:59:32.607681Z","shell.execute_reply.started":"2024-03-03T19:59:32.595435Z","shell.execute_reply":"2024-03-03T19:59:32.606956Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    params:\n        images : list of images to display\n    return:\n        None\n'''\ndef display_image_grid(images):\n    plt.title(\"Plot Images\")\n    plt.axis('off')\n    plt.imshow(np.concatenate(images, axis=1))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.609259Z","iopub.execute_input":"2024-03-03T19:59:32.609591Z","iopub.status.idle":"2024-03-03T19:59:32.617819Z","shell.execute_reply.started":"2024-03-03T19:59:32.609565Z","shell.execute_reply":"2024-03-03T19:59:32.617014Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    changing current working path to first-order-model repo.\n'''\nprev_path = os.getcwd()\nos.chdir(\"Projectmldl\")","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.619116Z","iopub.execute_input":"2024-03-03T19:59:32.619481Z","iopub.status.idle":"2024-03-03T19:59:32.629208Z","shell.execute_reply.started":"2024-03-03T19:59:32.619446Z","shell.execute_reply":"2024-03-03T19:59:32.628403Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading pretrained model\n- model is created using config file and model checkpoints are loaded.\n- We have two models:\n    1. keypoint detector\n    2. generator model","metadata":{"editable":false}},{"cell_type":"code","source":"config_path = \"config/vox-256.yaml\"\ncheckpoint_path = \"../../input/checkpointaftertraining/checkpointFinal.pth.tar\"","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.630263Z","iopub.execute_input":"2024-03-03T19:59:32.630526Z","iopub.status.idle":"2024-03-03T19:59:32.640097Z","shell.execute_reply.started":"2024-03-03T19:59:32.630501Z","shell.execute_reply":"2024-03-03T19:59:32.639384Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ffmpeg-python\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:32.641224Z","iopub.execute_input":"2024-03-03T19:59:32.641545Z","iopub.status.idle":"2024-03-03T19:59:39.634265Z","shell.execute_reply.started":"2024-03-03T19:59:32.641473Z","shell.execute_reply":"2024-03-03T19:59:39.633278Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from demo import load_checkpoints, make_animation\n\ngenerator, kp_detector = load_checkpoints(\n    config_path=config_path, \n    checkpoint_path=checkpoint_path\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:39.635655Z","iopub.execute_input":"2024-03-03T19:59:39.635972Z","iopub.status.idle":"2024-03-03T19:59:45.404487Z","shell.execute_reply.started":"2024-03-03T19:59:39.635938Z","shell.execute_reply":"2024-03-03T19:59:45.403713Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Source image \n\n- source image is loaded from path in system\n- using a driving video we animate source image","metadata":{"editable":false}},{"cell_type":"code","source":"source_image_path = \"/kaggle/input/gagang/WhatsApp Image 2024-03-03 at 20.18.34.jpeg\"\ndriving_video_path = \"../../input/first-order-motion/10.mp4\"","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:45.405761Z","iopub.execute_input":"2024-03-03T19:59:45.406052Z","iopub.status.idle":"2024-03-03T19:59:45.409672Z","shell.execute_reply.started":"2024-03-03T19:59:45.406024Z","shell.execute_reply":"2024-03-03T19:59:45.408746Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_image = imread(source_image_path, size=(256, 256))\ndriving_video = vidread(driving_video_path, size=(256,256))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:45.410829Z","iopub.execute_input":"2024-03-03T19:59:45.411144Z","iopub.status.idle":"2024-03-03T19:59:45.779089Z","shell.execute_reply.started":"2024-03-03T19:59:45.411104Z","shell.execute_reply":"2024-03-03T19:59:45.77831Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML(display(source_image, driving_video).to_html5_video())","metadata":{"execution":{"iopub.status.busy":"2024-03-03T19:59:45.780447Z","iopub.execute_input":"2024-03-03T19:59:45.780815Z","iopub.status.idle":"2024-03-03T20:00:02.8894Z","shell.execute_reply.started":"2024-03-03T19:59:45.780775Z","shell.execute_reply":"2024-03-03T20:00:02.888481Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"here we generate animated video of source image using motion of driving image","metadata":{"editable":false}},{"cell_type":"code","source":"# with relative = True (source image is animated relative to transforms of itself)\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=True)\nHTML(display(source_image, driving_video, predictions).to_html5_video())","metadata":{"execution":{"iopub.status.busy":"2024-03-03T20:00:02.890888Z","iopub.execute_input":"2024-03-03T20:00:02.891264Z","iopub.status.idle":"2024-03-03T20:00:49.491807Z","shell.execute_reply.started":"2024-03-03T20:00:02.891224Z","shell.execute_reply":"2024-03-03T20:00:49.490945Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = \"../got03.avi\"\nvidsave(save_path, predictions, fps=20, size=(256,256))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T20:00:49.493425Z","iopub.execute_input":"2024-03-03T20:00:49.493719Z","iopub.status.idle":"2024-03-03T20:00:50.351464Z","shell.execute_reply.started":"2024-03-03T20:00:49.493688Z","shell.execute_reply":"2024-03-03T20:00:50.350654Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# with relative = False (source image is animated with respect to transform of driving video)\npredictions = make_animation(source_image, driving_video, generator, kp_detector, relative=False,\n                            adapt_movement_scale=False)\nHTML(display(source_image, driving_video, predictions).to_html5_video())","metadata":{"execution":{"iopub.status.busy":"2024-03-03T20:00:50.352825Z","iopub.execute_input":"2024-03-03T20:00:50.353221Z","iopub.status.idle":"2024-03-03T20:01:35.949875Z","shell.execute_reply.started":"2024-03-03T20:00:50.353177Z","shell.execute_reply":"2024-03-03T20:01:35.948912Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = make_animation(source_image, driving_video, generator, kp_detector, relative=False, \n                             adapt_movement_scale=True)\nHTML(display(source_image, driving_video, predictions).to_html5_video())","metadata":{"execution":{"iopub.status.busy":"2024-03-03T20:01:35.951738Z","iopub.execute_input":"2024-03-03T20:01:35.952134Z"},"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Face detection to crop faces from image\n- It uses faces haarcascde to detect faces which is fast and give decent results.\n- We detect all faces and return list of crops of these faces.","metadata":{"editable":false}},{"cell_type":"code","source":"'''\n    params:\n        image : image to crop faces from\n        haarcascade_path : path to haarcascde xml file\n        size : size of cropped face images\n        margin_around : margin around detect box around face.\n            this is used to include some parts around faces like hair, neck soulders etc. value is tuned based on output needed.\n    return:\n        list of cropped images of faces\n'''\ndef crop_faces(image, haarcascade_path, size=(256,256), margin_around=50):\n    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n    detector = cv2.CascadeClassifier(haarcascade_path)\n    rects = detector.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=10, minSize=(30,30), flags=cv2.CASCADE_SCALE_IMAGE)\n    crop_images = []\n    for x, y, w, h in rects:\n        a = 0 if y - margin_around < 0 else y - margin_around\n        b = 0 if x - margin_around < 0 else x - margin_around\n        img = image[a:y + h + margin_around, b:x + w + margin_around]\n        img = cv2.resize(img, size)\n        crop_images.append(img)\n    return crop_images","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"downloading face haarcascade xml file from opencv github","metadata":{"editable":false}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Source Image from URL\n- loading image from a internet using its url.","metadata":{"editable":false}},{"cell_type":"code","source":"source_image_url = \"https://tse1.mm.bing.net/th?id=OIP.Y2JUsTgVo9B5FlgxAxytoQAAAA&pid=Api&P=0&h=180\"\ndriving_video_path = \"../../input/first-order-motion/00.mp4\"","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_image = imread(source_image_url, size=None, scale=False)\ndriving_video = vidread(driving_video_path, size=(256,256))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_image_grid([source_image])","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haarcascade_path = \"haarcascade_frontalface_default.xml\"\nmargin_around = 20","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Get all cropped face images from source image to transfer motion from driving video.","metadata":{"editable":false}},{"cell_type":"code","source":"crop_images = crop_faces(source_image, haarcascade_path=haarcascade_path, size=(256,256), margin_around=margin_around)\ncrop_images = np.array(crop_images)/255.0","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Number of Faces in image: \", len(crop_images))\ndisplay_image_grid(crop_images)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Select a cropped image from all cropped faces we get using its index","metadata":{"editable":false}},{"cell_type":"code","source":"face_index = 0","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HTML(display(crop_images[face_index], driving_video).to_html5_video())","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"creating and saving animated video based on motion from driving video","metadata":{"editable":false}},{"cell_type":"code","source":"predictions = make_animation(crop_images[face_index], driving_video, generator, kp_detector, relative=True)\nHTML(display(crop_images[face_index], driving_video, predictions).to_html5_video())","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_path = \"../messi.avi\"\nvidsave(save_path, predictions, fps=20, size=(256,256))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(prev_path)\n!rm -rf first-order-model","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}